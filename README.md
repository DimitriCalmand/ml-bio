# Classification des Maladies de Peau - HAM10000

Application de classification automatique des maladies de peau utilisant le dataset HAM10000 avec des fonctionnalitÃ©s d'interprÃ©tabilitÃ© (XAI).

## Description

Ce projet utilise le deep learning (Transfer Learning avec MobileNetV2) pour classifier 7 types de lÃ©sions cutanÃ©es :

| Code | Maladie | Type |
|------|---------|------|
| **mel** | Melanoma | ğŸ”´ CancÃ©reux |
| **bcc** | Basal Cell Carcinoma | ğŸ”´ CancÃ©reux |
| **akiec** | Actinic Keratosis | ğŸŸ  PrÃ©-cancÃ©reux |
| **bkl** | Benign Keratosis | ğŸŸ¢ BÃ©nin |
| **nv** | Melanocytic Nevus | ğŸŸ¢ BÃ©nin |
| **df** | Dermatofibroma | ğŸŸ¢ BÃ©nin |
| **vasc** | Vascular Lesion | ğŸŸ¢ BÃ©nin |

## FonctionnalitÃ©s

- âœ… **Classification automatique** avec MobileNetV2 (Transfer Learning)
- âœ… **Fine-tuning** en deux phases pour de meilleures performances
- âœ… **Gestion du dÃ©sÃ©quilibre** des classes avec class weights
- âœ… **Augmentation de donnÃ©es** (rotation, flip, zoom, etc.)
- âœ… **InterprÃ©tabilitÃ© avec Grad-CAM** - Visualisation des rÃ©gions d'attention
- âœ… **InterprÃ©tabilitÃ© avec Grad-CAM++** - AmÃ©lioration de Grad-CAM
- âœ… **InterprÃ©tabilitÃ© avec LIME** - Explications locales
- âœ… **Rapports cliniques** - Visualisations adaptÃ©es au contexte mÃ©dical
- âœ… **Optimisation des seuils** pour classes critiques (mÃ©lanome)

## Installation

```bash
# Cloner le projet
git clone <repository-url>
cd ml-bio

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## Configuration Kaggle

Pour tÃ©lÃ©charger le dataset, configurez votre API Kaggle :

1. CrÃ©ez un compte sur [Kaggle](https://www.kaggle.com/)
2. Allez dans Account > API > Create New API Token
3. Placez le fichier `kaggle.json` dans `~/.kaggle/`
4. DÃ©finissez les permissions : `chmod 600 ~/.kaggle/kaggle.json`

## Utilisation

### 1. TÃ©lÃ©charger et prÃ©parer les donnÃ©es

```bash
python src/download_data.py
```

### 2. EntraÃ®ner le modÃ¨le

```bash
python src/train.py
```

### 3. Ã‰valuer le modÃ¨le

```bash
python src/evaluate.py
```

### 4. GÃ©nÃ©rer des explications (XAI)

```bash
# Explication basique (Grad-CAM + LIME)
python src/generate_explanation.py path/to/image.jpg

# Rapport clinique complet
python src/generate_explanation.py path/to/image.jpg --clinical

# Toutes les mÃ©thodes d'explication
python src/generate_explanation.py path/to/image.jpg --methods gradcam gradcam++ lime

# Traitement par lot
python src/generate_explanation.py path/to/folder/ --batch

# LIME haute qualitÃ© (plus d'Ã©chantillons)
python src/generate_explanation.py path/to/image.jpg --lime-samples 2000
```

### 5. Tester les fonctionnalitÃ©s d'explication

```bash
# Test rapide sur une image alÃ©atoire
python src/test_explain.py

# Test sur une image spÃ©cifique
python src/test_explain.py --image path/to/image.jpg

# Test sur toutes les classes
python src/test_explain.py --all
```

## Structure du Projet

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # DonnÃ©es brutes HAM10000
â”‚   â””â”€â”€ processed/              # Images organisÃ©es par classe
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model_finetuned.keras  # Meilleur modÃ¨le (fine-tuned)
â”‚   â”œâ”€â”€ best_model.keras        # ModÃ¨le phase 1
â”‚   â”œâ”€â”€ class_mapping.json      # Mapping des classes
â”‚   â””â”€â”€ training_config.json    # Configuration d'entraÃ®nement
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ explanations/           # Visualisations XAI gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â””â”€â”€ evaluation_results.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ download_data.py        # TÃ©lÃ©chargement des donnÃ©es
â”‚   â”œâ”€â”€ model.py                # Architecture du modÃ¨le
â”‚   â”œâ”€â”€ train.py                # EntraÃ®nement (2 phases)
â”‚   â”œâ”€â”€ evaluate.py             # Ã‰valuation et mÃ©triques
â”‚   â”œâ”€â”€ explain.py              # Module XAI (Grad-CAM, LIME)
â”‚   â”œâ”€â”€ generate_explanation.py # CLI pour les explications
â”‚   â”œâ”€â”€ test_explain.py         # Tests des explications
â”‚   â””â”€â”€ threshold_optimizer.py  # Optimisation des seuils
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## InterprÃ©tabilitÃ© (XAI)

### Grad-CAM (Gradient-weighted Class Activation Mapping)

Grad-CAM visualise les rÃ©gions de l'image qui ont le plus contribuÃ© Ã  la dÃ©cision du modÃ¨le. Les zones en rouge/jaune indiquent une forte attention du modÃ¨le.

**RÃ©fÃ©rence**: Selvaraju et al., "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization", ICCV 2017.

### Grad-CAM++

Version amÃ©liorÃ©e de Grad-CAM avec une meilleure localisation, particuliÃ¨rement utile quand plusieurs instances du mÃªme type de lÃ©sion sont prÃ©sentes.

**RÃ©fÃ©rence**: Chattopadhyay et al., "Grad-CAM++: Generalized Gradient-based Visual Explanations", WACV 2018.

### LIME (Local Interpretable Model-agnostic Explanations)

LIME identifie les superpixels (rÃ©gions de l'image) qui influencent positivement ou nÃ©gativement la prÃ©diction. C'est une mÃ©thode model-agnostic.

**RÃ©fÃ©rence**: Ribeiro et al., "Why Should I Trust You?: Explaining the Predictions of Any Classifier", KDD 2016.

## Exemple d'utilisation Python

```python
from tensorflow import keras
from src.explain import ExplanationGenerator, create_clinical_explanation
import json

# Charger le modÃ¨le
model = keras.models.load_model("models/best_model_finetuned.keras")

# Charger les noms de classes
with open("models/class_mapping.json") as f:
    class_mapping = json.load(f)
class_names = [class_mapping[str(i)] for i in range(7)]

# GÃ©nÃ©rer une explication complÃ¨te
generator = ExplanationGenerator(model, class_names)
result = generator.explain_image(
    "path/to/image.jpg",
    methods=['gradcam', 'gradcam++', 'lime']
)

# CrÃ©er la visualisation
generator.create_explanation_figure(result, save_path="explanation.png")

# Ou gÃ©nÃ©rer un rapport clinique
create_clinical_explanation(
    model, "path/to/image.jpg", class_names,
    output_path="clinical_report.png"
)
```

## RÃ©sultats

Les rÃ©sultats d'entraÃ®nement et d'Ã©valuation sont sauvegardÃ©s dans `results/`:
- `confusion_matrix.png` - Matrice de confusion
- `roc_curves.png` - Courbes ROC par classe
- `classification_report.txt` - Rapport dÃ©taillÃ©
- `evaluation_results.json` - MÃ©triques JSON
- `explanations/` - Visualisations XAI

## Avertissement

âš ï¸ **AVERTISSEMENT MÃ‰DICAL**: Cet outil est une aide Ã  la dÃ©cision et ne remplace pas l'expertise d'un dermatologue. Tout diagnostic doit Ãªtre confirmÃ© par un examen clinique et une analyse histopathologique par un professionnel de santÃ© qualifiÃ©.
